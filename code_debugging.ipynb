{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLM did not return any concepts. Please check the model's response.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import networkx as nx\n",
    "import fitz\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from knowledge_graph import KnowledgeGraph\n",
    "from query_engine import QueryEngine\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import tqdm as tqdm\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "# from langchain_ollama import ChatOllama\n",
    "from langchain_community.llms import Ollama\n",
    "import json\n",
    "from pydantic import ValidationError\n",
    "\n",
    "class Concepts(BaseModel):\n",
    "    concepts_list: List[str] = Field(description=\"List of concepts\")\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "api_key = os.getenv(\"NOMIC_API_KEY\")\n",
    "\n",
    "path = \"E:/RAG_Project/data/Understanding_Climate_Change.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()\n",
    "documents = documents[:10]\n",
    "api_key = os.getenv(\"NOMIC_API_KEY\")\n",
    "# DocumentProcessor's process_documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "embeddings = NomicEmbeddings(model=\"nomic-embed-text-v1.5\")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "vector_store = FAISS.from_documents(splits, embeddings)\n",
    "graph = nx.Graph()\n",
    "\n",
    "knowledge_graph = KnowledgeGraph()\n",
    "# llm = ChatOpenAI(\n",
    "#     model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "#     base_url=\"http://localhost:1234/v1\",\n",
    "#     api_key=\"lm-studio\"\n",
    "# )\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "                 model=\"llama3.1\",\n",
    "                base_url = \"http://localhost:11434/v1\",\n",
    "                api_key = 'ollama'\n",
    "            )\n",
    "for i, split in enumerate(splits):\n",
    "    graph.add_node(i, content=split.page_content)\n",
    "\n",
    "texts = [split.page_content for split in splits]\n",
    "create_embedding = embeddings.embed_documents(texts)\n",
    "\n",
    "concept_cache = {}\n",
    "\n",
    "def _load_spacy_model():\n",
    "    try:\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "    except OSError:\n",
    "        print(\"Downloading spaCy model...\")\n",
    "        download(\"en_core_web_sm\")\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp = _load_spacy_model()\n",
    "\n",
    "content = split.page_content\n",
    "# print(content)\n",
    "doc = nlp(content)\n",
    "# print(doc)\n",
    "named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "# print(named_entities)\n",
    "concept_extraction_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    "        )\n",
    "\n",
    "\n",
    "# concept_chain = concept_extraction_prompt | llm.with_structured_output(Concepts)\n",
    "# general_concepts = concept_chain.invoke({\"text\": content})\n",
    "\n",
    "# # Check if the output is None\n",
    "# if general_concepts is None:\n",
    "#     print(\"The LLM did not return any concepts. Please check the model's response.\")\n",
    "# else:\n",
    "#     try:\n",
    "#         # Check if the LLM response is a stringified list\n",
    "#         if isinstance(general_concepts.concepts_list, str):\n",
    "#             concepts_list = json.loads(general_concepts.concepts_list)\n",
    "#         else:\n",
    "#             concepts_list = general_concepts.concepts_list\n",
    "\n",
    "#         # Validate the concepts using the Concepts model\n",
    "#         concepts = Concepts(concepts_list=concepts_list)\n",
    "#         general_concepts = concepts.concepts_list\n",
    "#         print(general_concepts)\n",
    "\n",
    "#     except (json.JSONDecodeError, ValidationError, AttributeError) as e:\n",
    "#         print(f\"Error parsing concepts: {e}\")\n",
    "\n",
    "\n",
    "# llm.invoke(content)\n",
    "# general_concepts = content_runnable.invoke({\"text\": content})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw LLM Output: content=\"It seems like you've got a collection of environmental-related topics there! Let me break down the key points you mentioned:\\n\\n### Climate Change Mitigation Strategies\\n1. **Energy-Efficient Solutions**: This encompasses measures such as:\\n   - Renewable energy resources.\\n   - Energy conservation tools and technologies.\\n\\n2. **Greenhouse Gas Reduction**: Focuses on:\\n   a. **Energy Transition**: Moving or transitioning to greener sources, like solar, wind, and others.\\n   b. **Fuel Efficiency Enhancements** aimed at making vehicles consume less fuel, thereby reducing emissions.\\n3. **Indoor Cooling Systems with Reduced Pollution**: Emphasizes energy-efficient solutions, possibly tied in the future to newer technology in this segment or phase of development. This would also extend to greenhouses & controlled indoor spaces as we adapt more into sustainable solutions with AI/IT (if applicable), although currently, this doesn’t play a crucial indirect impact on such global issues.\\n4. **Caps and Pollution Controls**: Enforces limits (as mentioned – caps) along with standards or mechanisms against further environmental degradation, usually through legal mandates at state (locally administered where more flexible regulatory controls exist worldwide).\\n\\n5. **Community Engagement and Partizipationatory Planning for Green Measures -**\\n    Local level involvement is encouraged through such platforms because direct local-level decision making ensures community engagement via participatory planning.\\n\\n6/2021 addition: With a better emphasis & the inclusion from above,\\n**Partnerships in Urban Climate Mitigation: Green Banking**\\n\\nPartnership initiatives are starting, where partnerships and collaborations will not only help but expedite progress to an entirely “climate neutral state.”\\nThe banking community is stepping through offering loans – on such condition - at reasonable interest so businesses & institutions may borrow the finances they so desperately needed by greenifying the urban climate conditions; promoting greener urban landscapes.\\n\\nThe above summary highlights what strategies should be emphasized or targeted more upon in our mission towards a lower carbon footprint, a greenish cleaner, more sustainable globe.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 406, 'prompt_tokens': 99, 'total_tokens': 505}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None} id='run-0536d05d-32a4-41d4-8eee-072b4d2c7b47-0' usage_metadata={'input_tokens': 99, 'output_tokens': 406, 'total_tokens': 505}\n",
      "Extracted Text Content: It seems like you've got a collection of environmental-related topics there! Let me break down the key points you mentioned:\n",
      "\n",
      "### Climate Change Mitigation Strategies\n",
      "1. **Energy-Efficient Solutions**: This encompasses measures such as:\n",
      "   - Renewable energy resources.\n",
      "   - Energy conservation tools and technologies.\n",
      "\n",
      "2. **Greenhouse Gas Reduction**: Focuses on:\n",
      "   a. **Energy Transition**: Moving or transitioning to greener sources, like solar, wind, and others.\n",
      "   b. **Fuel Efficiency Enhancements** aimed at making vehicles consume less fuel, thereby reducing emissions.\n",
      "3. **Indoor Cooling Systems with Reduced Pollution**: Emphasizes energy-efficient solutions, possibly tied in the future to newer technology in this segment or phase of development. This would also extend to greenhouses & controlled indoor spaces as we adapt more into sustainable solutions with AI/IT (if applicable), although currently, this doesn’t play a crucial indirect impact on such global issues.\n",
      "4. **Caps and Pollution Controls**: Enforces limits (as mentioned – caps) along with standards or mechanisms against further environmental degradation, usually through legal mandates at state (locally administered where more flexible regulatory controls exist worldwide).\n",
      "\n",
      "5. **Community Engagement and Partizipationatory Planning for Green Measures -**\n",
      "    Local level involvement is encouraged through such platforms because direct local-level decision making ensures community engagement via participatory planning.\n",
      "\n",
      "6/2021 addition: With a better emphasis & the inclusion from above,\n",
      "**Partnerships in Urban Climate Mitigation: Green Banking**\n",
      "\n",
      "Partnership initiatives are starting, where partnerships and collaborations will not only help but expedite progress to an entirely “climate neutral state.”\n",
      "The banking community is stepping through offering loans – on such condition - at reasonable interest so businesses & institutions may borrow the finances they so desperately needed by greenifying the urban climate conditions; promoting greener urban landscapes.\n",
      "\n",
      "The above summary highlights what strategies should be emphasized or targeted more upon in our mission towards a lower carbon footprint, a greenish cleaner, more sustainable globe.\n",
      "Validated Concepts: [\"It seems like you've got a collection of environmental-related topics there! Let me break down the key points you mentioned:\", '', '### Climate Change Mitigation Strategies', '1. **Energy-Efficient Solutions**: This encompasses measures such as:', '   - Renewable energy resources.', '   - Energy conservation tools and technologies.', '', '2. **Greenhouse Gas Reduction**: Focuses on:', '   a. **Energy Transition**: Moving or transitioning to greener sources, like solar, wind, and others.', '   b. **Fuel Efficiency Enhancements** aimed at making vehicles consume less fuel, thereby reducing emissions.', '3. **Indoor Cooling Systems with Reduced Pollution**: Emphasizes energy-efficient solutions, possibly tied in the future to newer technology in this segment or phase of development. This would also extend to greenhouses & controlled indoor spaces as we adapt more into sustainable solutions with AI/IT (if applicable), although currently, this doesn’t play a crucial indirect impact on such global issues.', '4. **Caps and Pollution Controls**: Enforces limits (as mentioned – caps) along with standards or mechanisms against further environmental degradation, usually through legal mandates at state (locally administered where more flexible regulatory controls exist worldwide).', '', '5. **Community Engagement and Partizipationatory Planning for Green Measures -**', '    Local level involvement is encouraged through such platforms because direct local-level decision making ensures community engagement via participatory planning.', '', '6/2021 addition: With a better emphasis & the inclusion from above,', '**Partnerships in Urban Climate Mitigation: Green Banking**', '', 'Partnership initiatives are starting, where partnerships and collaborations will not only help but expedite progress to an entirely “climate neutral state.”', 'The banking community is stepping through offering loans – on such condition - at reasonable interest so businesses & institutions may borrow the finances they so desperately needed by greenifying the urban climate conditions; promoting greener urban landscapes.', '', 'The above summary highlights what strategies should be emphasized or targeted more upon in our mission towards a lower carbon footprint, a greenish cleaner, more sustainable globe.']\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import BaseMessage\n",
    "# Debugging: Run the LLM prompt and get the raw output\n",
    "raw_output = llm.invoke(content)  # Pass the text directly as a string\n",
    "# prompt_input = concept_extraction_prompt.format(text=content)\n",
    "# Check if we got any output\n",
    "if raw_output is None:\n",
    "    print(\"The LLM did not return any concepts. Please check the model's response.\")\n",
    "else:\n",
    "    print(\"Raw LLM Output:\", raw_output)  # Print the raw output for debugging\n",
    "\n",
    "    try:\n",
    "        # Extract 'content' from the LLM response (raw_output)\n",
    "        if isinstance(raw_output, BaseMessage):\n",
    "            response_content = raw_output.content  # Only extract the actual text content\n",
    "        else:\n",
    "            raise ValueError(\"Invalid response format from the LLM.\")\n",
    "\n",
    "        # print(\"Extracted Text Content:\", response_content)\n",
    "\n",
    "        # Now, assume the 'response_content' contains concepts in textual form\n",
    "        general_concepts = response_content.splitlines()  # Split the text into lines as a simple approach\n",
    "\n",
    "        # Ensure the concepts list is valid\n",
    "        concepts = Concepts(concepts_list=general_concepts)\n",
    "        print(\"Validated Concepts:\", concepts.concepts_list)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError, AttributeError, ValueError) as e:\n",
    "        print(f\"Error parsing concepts: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw LLM Output: content='Here are the key concepts extracted from the text (excluding named entities):\\n\\n1. **Regulation**\\n2. **Protection**\\n\\n(mediated concepts implied by regulation)\\n\\n1. **Pollution prevention/management/mitigation**\\n\\n(among others related to environment impacts not exhaustively stated as pollutuents, likely e.g., carbon, water contaminants - though note non-specific word choice so no certainty here.) \\n\\n2. **Accountability/Enforcement**\\n3. **Efficacy** \\n4. * **Effective outcomes**\\n\\n(implied)' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 116, 'total_tokens': 226}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None} id='run-0a66490f-f079-4e61-b7a2-0f9142733243-0' usage_metadata={'input_tokens': 116, 'output_tokens': 110, 'total_tokens': 226}\n",
      "Validated Concepts: ['Here are the key concepts extracted from the text (excluding named entities):', '', '1. **Regulation**', '2. **Protection**', '', '(mediated concepts implied by regulation)', '', '1. **Pollution prevention/management/mitigation**', '', '(among others related to environment impacts not exhaustively stated as pollutuents, likely e.g., carbon, water contaminants - though note non-specific word choice so no certainty here.) ', '', '2. **Accountability/Enforcement**', '3. **Efficacy** ', '4. * **Effective outcomes**', '', '(implied)']\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import BaseMessage\n",
    "# Debugging: Run the LLM prompt and get the raw output\n",
    "\n",
    "nlp = _load_spacy_model()\n",
    "\n",
    "content = split.page_content\n",
    "# print(content)\n",
    "doc = nlp(content)\n",
    "# print(doc)\n",
    "named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "# print(named_entities)\n",
    "concept_extraction_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    "        )\n",
    "\n",
    "prompt_input = concept_extraction_prompt.format(text=content)\n",
    "raw_output = llm.invoke(prompt_input)  # Pass the text directly as a string\n",
    "\n",
    "# Check if we got any output\n",
    "if raw_output is None:\n",
    "    print(\"The LLM did not return any concepts. Please check the model's response.\")\n",
    "else:\n",
    "    print(\"Raw LLM Output:\", raw_output)  # Print the raw output for debugging\n",
    "\n",
    "    try:\n",
    "        # Extract 'content' from the LLM response (raw_output)\n",
    "        if isinstance(raw_output, BaseMessage):\n",
    "            response_content = raw_output.content  # Only extract the actual text content\n",
    "        else:\n",
    "            raise ValueError(\"Invalid response format from the LLM.\")\n",
    "\n",
    "        # print(\"Extracted Text Content:\", response_content)\n",
    "\n",
    "        # Now, assume the 'response_content' contains concepts in textual form\n",
    "        general_concepts = response_content.splitlines()  # Split the text into lines as a simple approach\n",
    "\n",
    "        # Ensure the concepts list is valid\n",
    "        concepts = Concepts(concepts_list=general_concepts)\n",
    "        print(\"Validated Concepts:\", concepts.concepts_list)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError, AttributeError, ValueError) as e:\n",
    "        print(f\"Error parsing concepts: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_concepts_and_entities(content, llm):\n",
    "    if content in concept_cache:\n",
    "        return concept_cache[content]\n",
    "    \n",
    "    # Extract named entities using spaCy\n",
    "    doc = nlp(content)\n",
    "    named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "    \n",
    "    # Extract general concepts using LLM\n",
    "    concept_extraction_prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    "    )\n",
    "    # concept_chain = concept_extraction_prompt | llm.with_structured_output(Concepts)\n",
    "    # general_concepts = concept_chain.invoke({\"text\": content}).concepts_list\n",
    "    prompt_input = concept_extraction_prompt.format(text=content)\n",
    "    raw_output = llm.invoke(prompt_input)  # Pass the text directly as a string\n",
    "\n",
    "    # Check if we got any output\n",
    "    if raw_output is None:\n",
    "        print(\"The LLM did not return any concepts. Please check the model's response.\")\n",
    "    else:\n",
    "        print(\"Raw LLM Output:\", raw_output)  # Print the raw output for debugging\n",
    "\n",
    "        try:\n",
    "            # Extract 'content' from the LLM response (raw_output)\n",
    "            if isinstance(raw_output, BaseMessage):\n",
    "                response_content = raw_output.content  # Only extract the actual text content\n",
    "            else:\n",
    "                raise ValueError(\"Invalid response format from the LLM.\")\n",
    "\n",
    "            # print(\"Extracted Text Content:\", response_content)\n",
    "\n",
    "            # Now, assume the 'response_content' contains concepts in textual form\n",
    "            general_concept = response_content.splitlines()  # Split the text into lines as a simple approach\n",
    "\n",
    "            # Ensure the concepts list is valid\n",
    "            concepts = Concepts(concepts_list=general_concept)\n",
    "            general_concepts = concepts.concepts_list\n",
    "            # print(\"Validated Concepts:\", concepts.concepts_list)\n",
    "\n",
    "        except (json.JSONDecodeError, ValidationError, AttributeError, ValueError) as e:\n",
    "            print(f\"Error parsing concepts: {e}\")\n",
    "            \n",
    "            # Combine named entities and general concepts\n",
    "        all_concepts = list(set(named_entities + general_concepts))\n",
    "        \n",
    "        concept_cache[content] = all_concepts\n",
    "        return all_concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_concepts(splits, llm):\n",
    "    \"\"\"\n",
    "    Extracts concepts for all document splits using multi-threading.\n",
    "    \n",
    "    Args:\n",
    "    - splits (list): A list of document splits.\n",
    "    - llm: An instance of a large language model.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_node = {executor.submit(_extract_concepts_and_entities, split.page_content, llm): i \n",
    "                            for i, split in enumerate(splits)}\n",
    "        \n",
    "        for future in tqdm(as_completed(future_to_node), total=len(splits), desc=\"Extracting concepts and entities\"):\n",
    "            node = future_to_node[future]\n",
    "            concepts = future.result()\n",
    "            graph.nodes[node]['concepts'] = concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def _compute_similarities(self, embeddings):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity matrix for the embeddings.\n",
    "    \n",
    "    Args:\n",
    "    - embeddings (numpy.ndarray): An array of embeddings.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: A cosine similarity matrix for the embeddings.\n",
    "    \"\"\"\n",
    "    return cosine_similarity(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_edges(self, embeddings):\n",
    "    \"\"\"\n",
    "    Adds edges to the graph based on the similarity of embeddings and shared concepts.\n",
    "    \n",
    "    Args:\n",
    "    - embeddings (numpy.ndarray): An array of embeddings for the document splits.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    edges_threshold = 0.8\n",
    "    similarity_matrix = _compute_similarities(embeddings)\n",
    "    num_nodes = len(graph.nodes)\n",
    "    \n",
    "    for node1 in tqdm(range(num_nodes), desc=\"Adding edges\"):\n",
    "        for node2 in range(node1 + 1, num_nodes):\n",
    "            similarity_score = similarity_matrix[node1][node2]\n",
    "            if similarity_score > edges_threshold:\n",
    "                shared_concepts = set(graph.nodes[node1]['concepts']) & set(graph.nodes[node2]['concepts'])\n",
    "                edge_weight = _calculate_edge_weight(node1, node2, similarity_score, shared_concepts)\n",
    "                graph.add_edge(node1, node2, weight=edge_weight, \n",
    "                                    similarity=similarity_score,\n",
    "                                    shared_concepts=list(shared_concepts))\n",
    "\n",
    "def _calculate_edge_weight(node1, node2, similarity_score, shared_concepts, alpha=0.7, beta=0.3):\n",
    "    \"\"\"\n",
    "    Calculates the weight of an edge based on similarity score and shared concepts.\n",
    "    \n",
    "    Args:\n",
    "    - node1 (int): The first node.\n",
    "    - node2 (int): The second node.\n",
    "    - similarity_score (float): The similarity score between the nodes.\n",
    "    - shared_concepts (set): The set of shared concepts between the nodes.\n",
    "    - alpha (float, optional): The weight of the similarity score. Default is 0.7.\n",
    "    - beta (float, optional): The weight of the shared concepts. Default is 0.3.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The calculated weight of the edge.\n",
    "    \"\"\"\n",
    "    max_possible_shared = min(len(graph.nodes[node1]['concepts']), len(graph.nodes[node2]['concepts']))\n",
    "    normalized_shared_concepts = len(shared_concepts) / max_possible_shared if max_possible_shared > 0 else 0\n",
    "    return alpha * similarity_score + beta * normalized_shared_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '   - Energy conservation tools and technologies.',\n",
       " 'The banking community is stepping through offering loans – on such condition - at reasonable interest so businesses & institutions may borrow the finances they so desperately needed by greenifying the urban climate conditions; promoting greener urban landscapes.',\n",
       " 'Local and Community Initiatives  \\nUrban Climate Action  \\nCities',\n",
       " '2. **Greenhouse Gas Reduction**: Focuses on:',\n",
       " 'Partnership initiatives are starting, where partnerships and collaborations will not only help but expedite progress to an entirely “climate neutral state.”',\n",
       " '   b. **Fuel Efficiency Enhancements** aimed at making vehicles consume less fuel, thereby reducing emissions.',\n",
       " '1. **Energy-Efficient Solutions**: This encompasses measures such as:',\n",
       " '4. **Caps and Pollution Controls**: Enforces limits (as mentioned – caps) along with standards or mechanisms against further environmental degradation, usually through legal mandates at state (locally administered where more flexible regulatory controls exist worldwide).',\n",
       " '   a. **Energy Transition**: Moving or transitioning to greener sources, like solar, wind, and others.',\n",
       " '5. **Community Engagement and Partizipationatory Planning for Green Measures -**',\n",
       " '   - Renewable energy resources.',\n",
       " '    Local level involvement is encouraged through such platforms because direct local-level decision making ensures community engagement via participatory planning.',\n",
       " '**Partnerships in Urban Climate Mitigation: Green Banking**',\n",
       " '3. **Indoor Cooling Systems with Reduced Pollution**: Emphasizes energy-efficient solutions, possibly tied in the future to newer technology in this segment or phase of development. This would also extend to greenhouses & controlled indoor spaces as we adapt more into sustainable solutions with AI/IT (if applicable), although currently, this doesn’t play a crucial indirect impact on such global issues.',\n",
       " 'The above summary highlights what strategies should be emphasized or targeted more upon in our mission towards a lower carbon footprint, a greenish cleaner, more sustainable globe.',\n",
       " \"It seems like you've got a collection of environmental-related topics there! Let me break down the key points you mentioned:\",\n",
       " '### Climate Change Mitigation Strategies',\n",
       " '6/2021 addition: With a better emphasis & the inclusion from above,']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_concepts = list(set(named_entities + general_concepts))\n",
    "all_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have a personal name, but I'm an AI assistant designed to provide information and help with tasks. You can refer to me as Assistant or AI if you like!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 38, 'total_tokens': 74}, 'model_name': 'lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-90542874-3e33-4781-acab-bf8e5be3ff34-0', usage_metadata={'input_tokens': 38, 'output_tokens': 36, 'total_tokens': 74})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_extract_concepts_and_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_concepts_and_entities(content, llm):\n",
    "    \"\"\"\n",
    "    Extracts concepts and named entities from the content using spaCy and a large language model.\n",
    "    \n",
    "    Args:\n",
    "    - content (str): The content from which to extract concepts and entities.\n",
    "    - llm: An instance of a large language model.\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of extracted concepts and entities.\n",
    "    \"\"\"\n",
    "    if content in concept_cache:\n",
    "        return concept_cache[content]\n",
    "    \n",
    "    # Extract named entities using spaCy\n",
    "    doc = nlp(content)\n",
    "    named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "    \n",
    "    # Extract general concepts using LLM\n",
    "    concept_extraction_prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    "    )\n",
    "    concept_chain = concept_extraction_prompt | llm.with_structured_output(Concepts)\n",
    "    general_concepts = concept_chain.invoke({\"text\": content}).concepts_list\n",
    "    \n",
    "    # Combine named entities and general concepts\n",
    "    all_concepts = list(set(named_entities + general_concepts))\n",
    "    \n",
    "    concept_cache[content] = all_concepts\n",
    "    return all_concepts\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future_to_node = {executor.submit(_extract_concepts_and_entities, split.page_content, llm): i \n",
    "                        for i, split in enumerate(splits)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
