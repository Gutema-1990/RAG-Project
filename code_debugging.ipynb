{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are the key concepts (excluding named entities) extracted from the text:\\n\\n1. Climate action\\n2. Urbanization\\n3. Population density\\n4. Economic activities\\n5. Sustainability\\n6. Transportation systems\\n7. Green building\\n8. Infrastructure resilience\\n9. Community engagement\\n10. Participatory planning'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import networkx as nx\n",
    "import fitz\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from knowledge_graph import KnowledgeGraph\n",
    "from query_engine import QueryEngine\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import tqdm as tqdm\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "from pydantic import BaseModel, Field\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "# Define the Concepts class\n",
    "class Concepts(BaseModel):\n",
    "    concepts_list: List[str] = Field(description=\"List of concepts\")\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "api_key = os.getenv(\"NOMIC_API_KEY\")\n",
    "\n",
    "path = \"/home/name-1/AI-Agent/RAG_Project/RAG_Project/data/Understanding_Climate_Change.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()\n",
    "documents = documents[:10]\n",
    "api_key = os.getenv(\"NOMIC_API_KEY\")\n",
    "# DocumentProcessor's process_documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "embeddings = NomicEmbeddings(model=\"nomic-embed-text-v1.5\")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "vector_store = FAISS.from_documents(splits, embeddings)\n",
    "graph = nx.Graph()\n",
    "\n",
    "knowledge_graph = KnowledgeGraph()\n",
    "llm = ChatOpenAI(\n",
    "    model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "    base_url=\"http://10.2.125.37:1234/v1\",\n",
    "    api_key=\"lm-studio\"\n",
    ")\n",
    "\n",
    "for i, split in enumerate(splits):\n",
    "    graph.add_node(i, content=split.page_content)\n",
    "\n",
    "texts = [split.page_content for split in splits]\n",
    "create_embedding = embeddings.embed_documents(texts)\n",
    "\n",
    "concept_cache = {}\n",
    "\n",
    "def _load_spacy_model():\n",
    "    try:\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "    except OSError:\n",
    "        print(\"Downloading spaCy model...\")\n",
    "        download(\"en_core_web_sm\")\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp = _load_spacy_model()\n",
    "\n",
    "content = split.page_content\n",
    "# print(content)\n",
    "doc = nlp(content)\n",
    "# print(doc)\n",
    "named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "# print(named_entities)\n",
    "concept_extraction_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    "        )\n",
    "\n",
    "\n",
    "concept_chain = concept_extraction_prompt | llm\n",
    "general_concepts = concept_chain.invoke({\"text\": content}).content\n",
    "# llm.invoke(content)\n",
    "# general_concepts = content_runnable.invoke({\"text\": content})\n",
    "general_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sustainability', 'Climate action', 'Population density', 'Economic activities', 'Transportation systems', 'Green building standards', 'Infrastructure resilience', 'Community engagement', 'Participatory planning', 'Conservation', 'Pollution controls']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4678/440199384.py:14: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator('key_concepts', pre=True, always=True)\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional\n",
    "import re\n",
    "\n",
    "class AIMessage(BaseModel):\n",
    "    content: str\n",
    "    additional_kwargs: Optional[dict]\n",
    "    response_metadata: Optional[dict]\n",
    "    id: str\n",
    "    usage_metadata: Optional[dict]\n",
    "\n",
    "    key_concepts: List[str] = Field(default_factory=list)\n",
    "\n",
    "    @validator('key_concepts', pre=True, always=True)\n",
    "    def extract_key_concepts(cls, v, values):\n",
    "        content = values.get('content', '')\n",
    "        # Regex to find the list after the introductory text\n",
    "        match = re.search(r\"Here are the key concepts.*?:\\s*(\\d\\..*)\", content, re.DOTALL)\n",
    "        if match:\n",
    "            # Extract the list of concepts and clean up the formatting\n",
    "            list_text = match.group(1)\n",
    "            concepts = [item.strip().split('. ', 1)[-1] for item in list_text.split('\\n') if '. ' in item]\n",
    "            return concepts\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "message_data = {\n",
    "    'content': 'Here are the key concepts (excluding named entities) extracted from the text:\\n\\n1. Sustainability\\n2. Climate action\\n3. Population density\\n4. Economic activities\\n5. Transportation systems\\n6. Green building standards\\n7. Infrastructure resilience\\n8. Community engagement\\n9. Participatory planning\\n10. Conservation\\n11. Pollution controls',\n",
    "    'additional_kwargs': {'refusal': None},\n",
    "    'response_metadata': {\n",
    "        'token_usage': {'completion_tokens': 69, 'prompt_tokens': 138, 'total_tokens': 207},\n",
    "        'model_name': 'lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf',\n",
    "        'system_fingerprint': None,\n",
    "        'finish_reason': 'stop',\n",
    "        'logprobs': None\n",
    "    },\n",
    "    'id': 'run-7ca6460b-ed26-4a18-8d3a-d0db3be20e0f-0',\n",
    "    'usage_metadata': {'input_tokens': 138, 'output_tokens': 69, 'total_tokens': 207}\n",
    "}\n",
    "\n",
    "ai_message = AIMessage(**message_data)\n",
    "print(ai_message.key_concepts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = split.page_content\n",
    "# print(content)\n",
    "doc = nlp(content)\n",
    "# print(doc)\n",
    "named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "# print(named_entities)\n",
    "concept_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Extract key concepts (excluding named entities) from the following text and return as JSON:\\n\\n{text}\\n\\nKey concepts:\"\n",
    ")\n",
    "llm_in = llm.with_structured_output(Concepts)\n",
    "llm_x = llm_in.invoke(content)\n",
    "# concept_chain = concept_extraction_prompt | llm.with_structured_output(Concepts)\n",
    "# general_concepts = concept_chain.invoke({\"text\": content}).concepts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "class KeyConceptsOutput(BaseModel):\n",
    "    key_concepts: list[str]\n",
    "\n",
    "    @classmethod\n",
    "    def parse_response(cls, response_text: str):\n",
    "        # Attempt to parse as JSON\n",
    "        try:\n",
    "            data = json.loads(response_text)\n",
    "            return cls(**data)\n",
    "        except json.JSONDecodeError:\n",
    "            # Handle cases where the model did not output valid JSON\n",
    "            return None\n",
    "\n",
    "\n",
    "class LMStudioModelWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def with_structured_output(self, input_text: str):\n",
    "        # Create a prompt that requests structured output\n",
    "        structured_prompt = f\"\"\"\n",
    "        Extract the key concepts from the following text and return them in a structured JSON format:\n",
    "        {{\n",
    "            \"key_concepts\": [\"Concept 1\", \"Concept 2\", \"Concept 3\", ...]\n",
    "        }}\n",
    "\n",
    "        Text:\n",
    "        {input_text}\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the response from the model\n",
    "        response = self.model.invoke({\"text\": structured_prompt})\n",
    "\n",
    "        # Parse the response using the Pydantic model\n",
    "        return KeyConceptsOutput.parse_response(response)\n",
    "\n",
    "# Usage\n",
    "lm_model = LMStudioModelWrapper(llm)\n",
    "result = lm_model.with_structured_output(\"Your input text here\")\n",
    "\n",
    "if result:\n",
    "    print(result.key_concepts)\n",
    "else:\n",
    "    print(\"Failed to parse structured output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _extract_concepts_and_entities(content, llm):\n",
    "    if content in concept_cache:\n",
    "        return concept_cache[content]\n",
    "    \n",
    "    doc = nlp(content)\n",
    "    named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "    \n",
    "    concept_extraction_prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    "    )\n",
    "    concept_chain = concept_extraction_prompt | llm.with_structured_output(Concepts)\n",
    "    general_concepts = concept_chain.invoke({\"text\": content}).concepts_list\n",
    "    \n",
    "    all_concepts = list(set(named_entities + general_concepts))\n",
    "    concept_cache[content] = all_concepts\n",
    "    return all_concepts\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future_to_node = {executor.submit(_extract_concepts_and_entities, split.page_content, llm): i \n",
    "                     for i, split in enumerate(splits)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LMStudioModelWrapper' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model = ChatOpenAI(temperature=0.0)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m input_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is your name?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m(input_string)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LMStudioModelWrapper' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "# model = ChatOpenAI(temperature=0.0)\n",
    "input_string = \"What is your name?\"\n",
    "\n",
    "llm.invoke(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_concepts_and_entities(content, llm):\n",
    "    \"\"\"\n",
    "    Extracts concepts and named entities from the content using spaCy and a large language model.\n",
    "    \n",
    "    Args:\n",
    "    - content (str): The content from which to extract concepts and entities.\n",
    "    - llm: An instance of a large language model.\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of extracted concepts and entities.\n",
    "    \"\"\"\n",
    "    if content in concept_cache:\n",
    "        return concept_cache[content]\n",
    "    \n",
    "    # Extract named entities using spaCy\n",
    "    doc = nlp(content)\n",
    "    named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "    \n",
    "    # Extract general concepts using LLM\n",
    "    concept_extraction_prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    "    )\n",
    "    concept_chain = concept_extraction_prompt | llm.with_structured_output(Concepts)\n",
    "    general_concepts = concept_chain.invoke({\"text\": content}).concepts_list\n",
    "    \n",
    "    # Combine named entities and general concepts\n",
    "    all_concepts = list(set(named_entities + general_concepts))\n",
    "    \n",
    "    concept_cache[content] = all_concepts\n",
    "    return all_concepts\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future_to_node = {executor.submit(_extract_concepts_and_entities, split.page_content, llm): i \n",
    "                        for i, split in enumerate(splits)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
