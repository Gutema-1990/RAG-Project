{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "# from openai.error import RateLimitError\n",
    "from langchain_openai import ChatOpenAI\n",
    "import networkx as nx\n",
    "import fitz\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from knowledge_graph import KnowledgeGraph\n",
    "from query_engine import QueryEngine\n",
    "from langchain.document_loaders import  PyPDFLoader\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import tqdm as tqdm\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# from typing import \n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "class Concepts(BaseModel):\n",
    "    concepts_list: List[str] = Field(description=\"List of concepts\")\n",
    "\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "api_key = os.getenv(\"NOMIC_API_KEY\")\n",
    "\n",
    "path = \"/home/name-1/AI-Agent/RAG_Project/RAG_Project/data/Understanding_Climate_Change.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()\n",
    "documents = documents[:10]\n",
    "\n",
    "# DocumentProcessor's process_documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "embeddings =  NomicEmbeddings(model=\"nomic-embed-text-v1.5\",)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "vector_store = FAISS.from_documents(splits, embeddings)\n",
    "graph = nx.Graph()\n",
    "\n",
    "knowledge_graph = KnowledgeGraph()\n",
    "llm = ChatOpenAI(\n",
    "                model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "                base_url=\"http://10.2.125.37:1234/v1\",\n",
    "                api_key=\"lm-studio\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(documents)\n",
    "vector_store = FAISS.from_documents(splits, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, split in enumerate(splits):\n",
    "    graph.add_node(i, content=split.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [split.page_content for split in splits]\n",
    "create_embedding = embeddings.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_cache = {}\n",
    "def _load_spacy_model():\n",
    "    \"\"\"\n",
    "    Loads the spaCy NLP model, downloading it if necessary.\n",
    "    \n",
    "    Args:\n",
    "    - None\n",
    "    \n",
    "    Returns:\n",
    "    - spacy.Language: An instance of a spaCy NLP model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "    except OSError:\n",
    "        print(\"Downloading spaCy model...\")\n",
    "        download(\"en_core_web_sm\")\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "nlp = _load_spacy_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_concepts_and_entities(content, llm):\n",
    "    \"\"\"\n",
    "    Extracts concepts and named entities from the content using spaCy and a large language model.\n",
    "    \n",
    "    Args:\n",
    "    - content (str): The content from which to extract concepts and entities.\n",
    "    - llm: An instance of a large language model.\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of extracted concepts and entities.\n",
    "    \"\"\"\n",
    "    if content in concept_cache:\n",
    "        return concept_cache[content]\n",
    "    \n",
    "    # Extract named entities using spaCy\n",
    "    doc = nlp(content)\n",
    "    named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "    \n",
    "    # Extract general concepts using LLM\n",
    "    concept_extraction_prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    "    )\n",
    "    concept_chain = concept_extraction_prompt | llm.with_structured_output(Concepts)\n",
    "    general_concepts = concept_chain.invoke({\"text\": content}).concepts_list\n",
    "    \n",
    "    # Combine named entities and general concepts\n",
    "    all_concepts = list(set(named_entities + general_concepts))\n",
    "    \n",
    "    concept_cache[content] = all_concepts\n",
    "    return all_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = split.page_content\n",
    "if content in concept_cache:\n",
    "    all_concepts = concept_cache[content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(content)\n",
    "named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], template='Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    ")\n",
    "concept_extraction_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42891/548881107.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=concept_extraction_prompt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['text'], template='Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7e6ce25d7490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7e6ce3a75010>, root_client=<openai.OpenAI object at 0x7e6ce1a6f010>, root_async_client=<openai.AsyncOpenAI object at 0x7e6ce25d7790>, model_name='lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF', openai_api_key=SecretStr('**********'), openai_api_base='http://10.2.125.37:1234/v1', openai_proxy=''))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.chains import LLMChain\n",
    "# llm_chain = LLMChain(llm=llm, prompt=concept_extraction_prompt)\n",
    "# llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], template='Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:')\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7e6ce25d7490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7e6ce3a75010>, root_client=<openai.OpenAI object at 0x7e6ce1a6f010>, root_async_client=<openai.AsyncOpenAI object at 0x7e6ce25d7790>, model_name='lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF', openai_api_key=SecretStr('**********'), openai_api_base='http://10.2.125.37:1234/v1', openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Concepts', 'description': '', 'parameters': {'type': 'object', 'properties': {'concepts_list': {'description': 'List of concepts', 'type': 'array', 'items': {'type': 'string'}}}, 'required': ['concepts_list']}}}], 'parallel_tool_calls': False, 'tool_choice': {'type': 'function', 'function': {'name': 'Concepts'}}})\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Concepts'>])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_chain = concept_extraction_prompt | llm.with_structured_output(Concepts)\n",
    "concept_chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'concepts_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m general_concepts \u001b[38;5;241m=\u001b[39m \u001b[43mconcept_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcepts_list\u001b[49m\n\u001b[1;32m      2\u001b[0m general_concepts\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'concepts_list'"
     ]
    }
   ],
   "source": [
    "general_concepts = concept_chain.invoke(content).concepts_list\n",
    "general_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m future_to_node \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(_extract_concepts_and_entities, split\u001b[38;5;241m.\u001b[39mpage_content, llm): i \n\u001b[1;32m      3\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m i, split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splits)}\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_to_node\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExtracting concepts and entities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      6\u001b[0m     node \u001b[38;5;241m=\u001b[39m future_to_node[future]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_to_node\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_extract_concepts_and_entities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_to_node\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExtracting concepts and entities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor() as executor:\n",
    "    future_to_node = {executor.submit(_extract_concepts_and_entities, split.page_content, llm): i \n",
    "                        for i, split in enumerate(splits)}\n",
    "    \n",
    "    for future in tqdm(as_completed(future_to_node), total=len(splits), desc=\"Extracting concepts and entities\"):\n",
    "        node = future_to_node[future]\n",
    "        concepts = future.result()\n",
    "        graph.nodes[node]['concepts'] = concepts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
