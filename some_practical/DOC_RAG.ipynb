{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "import os\n",
    "from langchain.document_loaders import  PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"NOMIC_API_KEY\")\n",
    "url = os.getenv(\"base_url\")\n",
    "doc_path = os.getenv(\"pdf_coop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"E:/RAG_Project/data/Understanding_Climate_Change.pdf\"\n",
    "loader = PyPDFLoader(doc_path)\n",
    "documents = loader.load()\n",
    "# documents = documents[:10]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'options: individual, joint , trust , \\nlegaliz ed c ooper atives, and or gani-\\nzations. \\nUnrestricted deposits and with-\\ndrawals, subjec t only t o regulations \\nimposed b y relevant author ities.\\nConvenienc e of se amless tr ansac -\\ntions thr ough v arious c hannels, \\nincluding A TM/POS car ds, int ernet \\nbanking, and mobile ser vices.\\nZero transac tion f ees, pr oviding our \\ncust omer s with a c ost-effective \\nand hassle -free b anking e xper i-\\nence.\\nPRODUC TS\\nIs an int erest-bearing option designed t o cat er \\nto a div erse range of cust omer s with a modest \\ninitial deposit of just Bir r 50. ORDINAR Y \\nPRODUC T OVERVIEW:SAVING A CCOUNT'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[7].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Preparedb y: Research & Development T eam MAY, 2024 PRODUCT CATALOG'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "document_texts = [doc.page_content for doc in documents]\n",
    "def clean_text(page_text):\n",
    "    # Example regex to remove header/footer by matching patterns (you can adjust based on the structure)\n",
    "    page_text = re.sub(r\"Header Pattern.*\\n\", \"\", page_text)\n",
    "    page_text = re.sub(r\"Footer Pattern.*\\n\", \"\", page_text)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    page_text = re.sub(r\"\\s+\", \" \", page_text)\n",
    "    \n",
    "    return page_text\n",
    "\n",
    "def fix_broken_words(text):\n",
    "    # Fix spaces between letters that should not have them (e.g., 'Preparedb y' -> 'Prepared by')\n",
    "    # Handle capital letters separating words (e.g., 'DevelopmentT eam' -> 'Development Team')\n",
    "    \n",
    "    # First, fix cases where letters are unnecessarily split by spaces\n",
    "    text = re.sub(r\"(\\w)\\s+(\\w)\", r\"\\1\\2\", text)\n",
    "    \n",
    "    # Then handle cases where there are multiple capital letters or titles (e.g., 'DevelopmentT eam')\n",
    "    text = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", text)\n",
    "    \n",
    "    # Fix where spaces are missing after punctuation (e.g., 'T eamMAY,2024' -> 'Team MAY, 2024')\n",
    "    text = re.sub(r\"([.,!?])(\\w)\", r\"\\1 \\2\", text)\n",
    "    \n",
    "    # Additional custom fixes for common PDF issues\n",
    "    text = re.sub(r\"(\\d)([A-Z])\", r\"\\1 \\2\", text)  # Handle numbers followed by words (e.g., '2024PRODUCT' -> '2024 PRODUCT')\n",
    "    \n",
    "    return text\n",
    "cleaned_pages = [clean_text(page) for page in document_texts]\n",
    "fixed_pages = [fix_broken_words(page) for page in cleaned_pages]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# splits = text_splitter.split_documents(documents)\n",
    "splits = text_splitter.split_text(\"\\n\".join(fixed_pages))\n",
    "splits[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "\n",
    "# Manually set the NLTK data path\n",
    "nltk.data.path.append(\"/home/name-1/nltk_data\")\n",
    "\n",
    "# Tokenize and fix text using the word tokenizer\n",
    "def nltk_fix_broken_words(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    corrected_text = \" \".join(tokens)\n",
    "    return corrected_text\n",
    "\n",
    "# Apply the function to clean the text\n",
    "fixed_pages = [nltk_fix_broken_words(page) for page in cleaned_pages]\n",
    "\n",
    "# Now split the fixed text using LangChain's text splitter\n",
    "splits = text_splitter.split_text(\"\\n\".join(fixed_pages))\n",
    "\n",
    "# Check the result\n",
    "print(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "\n",
    "embeddings =  NomicEmbeddings(model=\"nomic-embed-text-v1.5\",)\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\" \")))\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m splits:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI-Agent/RAG_Project/venv/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:273\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39madd_texts \u001b[38;5;241m!=\u001b[39m VectorStore\u001b[38;5;241m.\u001b[39madd_texts:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m--> 273\u001b[0m         ids \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# If there's at least one valid ID, we'll assume that IDs\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;66;03m# should be used.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n",
      "File \u001b[0;32m~/AI-Agent/RAG_Project/venv/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:273\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39madd_texts \u001b[38;5;241m!=\u001b[39m VectorStore\u001b[38;5;241m.\u001b[39madd_texts:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m--> 273\u001b[0m         ids \u001b[38;5;241m=\u001b[39m [\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# If there's at least one valid ID, we'll assume that IDs\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;66;03m# should be used.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    vector_store.add_documents(documents=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "llm = ChatOpenAI(\n",
    "                model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "                base_url=url,\n",
    "                api_key=\"lm-studio\"\n",
    "            )\n",
    "# Set up system prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "    \n",
    "])\n",
    "\n",
    "# Create the question-answer chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sheryl Baxter works for Rasmussen Group.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer= rag_chain.invoke({\"input\": \"which company does sheryl Baxter work for?\"})\n",
    "answer['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sheryl Baxter's subscription date is 2020-08-24. She has another entry with a different last name, Meyers, but the subscription date for Sheryl Baxter is this one.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sheryl\n",
    "answer= rag_chain.invoke({\"input\": \"what is  subscription date sheryl Baxter?\"})\n",
    "answer['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
